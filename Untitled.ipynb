{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc3052c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db3d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/sarim/Python data cleaning/Personal projects/Machine Learning project Retail sales forecast/Data/\"\n",
    "\n",
    "train = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "stores = pd.read_csv(os.path.join(data_path, \"stores.csv\"))\n",
    "features = pd.read_csv(os.path.join(data_path, \"features.csv\"))\n",
    "\n",
    "\n",
    "#print(train.head)\n",
    "#print(stores.head)\n",
    "#print(features.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d358b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge datasets\n",
    "df = train.merge(stores, on='Store').merge(features, on=['Store', 'Date'])\n",
    "\n",
    "# Convert Date column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort chronologically\n",
    "df = df.sort_values(by='Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39dba312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(data_path, \"cleaned_retail_data.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55d55846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the data is sorted by date and saved in the pc in cleaned retail data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78433044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff83d729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get unique store-dept pairs\n",
    "store_dept_pairs = df[['Store', 'Dept']].drop_duplicates()\n",
    "\n",
    "# Create a DataFrame to store forecasts + errors\n",
    "forecast_results = []\n",
    "\n",
    "print (forecast_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d438c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Training on Store 1, Dept 1\n",
      "✅ Done: Store 1, Dept 1\n",
      "🔄 Training on Store 35, Dept 3\n",
      "✅ Done: Store 35, Dept 3\n",
      "🔄 Training on Store 35, Dept 4\n",
      "✅ Done: Store 35, Dept 4\n",
      "🔄 Training on Store 35, Dept 5\n",
      "✅ Done: Store 35, Dept 5\n",
      "🔄 Training on Store 35, Dept 6\n",
      "✅ Done: Store 35, Dept 6\n",
      "🔄 Training on Store 35, Dept 7\n",
      "✅ Done: Store 35, Dept 7\n",
      "🔄 Training on Store 35, Dept 8\n",
      "✅ Done: Store 35, Dept 8\n",
      "🔄 Training on Store 35, Dept 9\n",
      "✅ Done: Store 35, Dept 9\n",
      "🔄 Training on Store 35, Dept 10\n",
      "✅ Done: Store 35, Dept 10\n",
      "🔄 Training on Store 35, Dept 2\n",
      "✅ Done: Store 35, Dept 2\n",
      "🔄 Training on Store 35, Dept 11\n",
      "✅ Done: Store 35, Dept 11\n",
      "🔄 Training on Store 35, Dept 13\n",
      "✅ Done: Store 35, Dept 13\n",
      "🔄 Training on Store 35, Dept 14\n",
      "✅ Done: Store 35, Dept 14\n",
      "🔄 Training on Store 35, Dept 16\n",
      "✅ Done: Store 35, Dept 16\n",
      "🔄 Training on Store 35, Dept 17\n",
      "✅ Done: Store 35, Dept 17\n",
      "🔄 Training on Store 35, Dept 18\n",
      "✅ Done: Store 35, Dept 18\n",
      "🔄 Training on Store 35, Dept 20\n",
      "✅ Done: Store 35, Dept 20\n",
      "🔄 Training on Store 35, Dept 21\n",
      "✅ Done: Store 35, Dept 21\n",
      "🔄 Training on Store 35, Dept 22\n",
      "✅ Done: Store 35, Dept 22\n",
      "🔄 Training on Store 35, Dept 12\n",
      "✅ Done: Store 35, Dept 12\n",
      "🔄 Training on Store 35, Dept 1\n",
      "✅ Done: Store 35, Dept 1\n",
      "🔄 Training on Store 7, Dept 1\n",
      "✅ Done: Store 7, Dept 1\n",
      "🔄 Training on Store 7, Dept 2\n",
      "✅ Done: Store 7, Dept 2\n",
      "🔄 Training on Store 7, Dept 22\n",
      "✅ Done: Store 7, Dept 22\n",
      "🔄 Training on Store 7, Dept 21\n",
      "✅ Done: Store 7, Dept 21\n",
      "🔄 Training on Store 7, Dept 20\n",
      "✅ Done: Store 7, Dept 20\n",
      "🔄 Training on Store 7, Dept 19\n",
      "✅ Done: Store 7, Dept 19\n",
      "🔄 Training on Store 7, Dept 18\n",
      "✅ Done: Store 7, Dept 18\n",
      "🔄 Training on Store 7, Dept 17\n",
      "✅ Done: Store 7, Dept 17\n",
      "🔄 Training on Store 7, Dept 16\n",
      "✅ Done: Store 7, Dept 16\n",
      "🔄 Training on Store 7, Dept 14\n",
      "✅ Done: Store 7, Dept 14\n",
      "🔄 Training on Store 7, Dept 13\n",
      "✅ Done: Store 7, Dept 13\n",
      "🔄 Training on Store 7, Dept 12\n",
      "✅ Done: Store 7, Dept 12\n",
      "🔄 Training on Store 7, Dept 11\n",
      "✅ Done: Store 7, Dept 11\n",
      "🔄 Training on Store 7, Dept 10\n",
      "✅ Done: Store 7, Dept 10\n",
      "🔄 Training on Store 7, Dept 9\n",
      "✅ Done: Store 7, Dept 9\n",
      "🔄 Training on Store 7, Dept 8\n",
      "✅ Done: Store 7, Dept 8\n",
      "🔄 Training on Store 7, Dept 7\n",
      "✅ Done: Store 7, Dept 7\n",
      "🔄 Training on Store 7, Dept 6\n",
      "✅ Done: Store 7, Dept 6\n",
      "🔄 Training on Store 7, Dept 5\n",
      "✅ Done: Store 7, Dept 5\n",
      "🔄 Training on Store 7, Dept 4\n",
      "✅ Done: Store 7, Dept 4\n",
      "🔄 Training on Store 7, Dept 3\n",
      "✅ Done: Store 7, Dept 3\n",
      "🔄 Training on Store 35, Dept 23\n",
      "✅ Done: Store 35, Dept 23\n",
      "🔄 Training on Store 7, Dept 23\n",
      "✅ Done: Store 7, Dept 23\n",
      "🔄 Training on Store 35, Dept 24\n",
      "✅ Done: Store 35, Dept 24\n",
      "🔄 Training on Store 35, Dept 26\n",
      "✅ Done: Store 35, Dept 26\n",
      "🔄 Training on Store 35, Dept 60\n",
      "✅ Done: Store 35, Dept 60\n",
      "🔄 Training on Store 35, Dept 67\n",
      "✅ Done: Store 35, Dept 67\n",
      "🔄 Training on Store 35, Dept 71\n",
      "✅ Done: Store 35, Dept 71\n",
      "🔄 Training on Store 35, Dept 72\n",
      "✅ Done: Store 35, Dept 72\n",
      "🔄 Training on Store 35, Dept 74\n",
      "✅ Done: Store 35, Dept 74\n",
      "🔄 Training on Store 35, Dept 78\n",
      "⚠️ Not enough data for Store 35, Dept 78\n",
      "🔄 Training on Store 35, Dept 79\n",
      "✅ Done: Store 35, Dept 79\n",
      "🔄 Training on Store 35, Dept 80\n",
      "✅ Done: Store 35, Dept 80\n",
      "🔄 Training on Store 35, Dept 59\n",
      "✅ Done: Store 35, Dept 59\n",
      "🔄 Training on Store 35, Dept 81\n",
      "✅ Done: Store 35, Dept 81\n",
      "🔄 Training on Store 35, Dept 83\n",
      "✅ Done: Store 35, Dept 83\n",
      "🔄 Training on Store 35, Dept 85\n",
      "✅ Done: Store 35, Dept 85\n",
      "🔄 Training on Store 35, Dept 87\n",
      "✅ Done: Store 35, Dept 87\n",
      "🔄 Training on Store 35, Dept 90\n",
      "✅ Done: Store 35, Dept 90\n",
      "🔄 Training on Store 35, Dept 91\n",
      "✅ Done: Store 35, Dept 91\n",
      "🔄 Training on Store 35, Dept 92\n",
      "✅ Done: Store 35, Dept 92\n",
      "🔄 Training on Store 35, Dept 93\n",
      "✅ Done: Store 35, Dept 93\n",
      "🔄 Training on Store 35, Dept 95\n",
      "✅ Done: Store 35, Dept 95\n",
      "🔄 Training on Store 35, Dept 82\n",
      "✅ Done: Store 35, Dept 82\n",
      "🔄 Training on Store 35, Dept 58\n",
      "✅ Done: Store 35, Dept 58\n",
      "🔄 Training on Store 35, Dept 56\n",
      "✅ Done: Store 35, Dept 56\n",
      "🔄 Training on Store 35, Dept 55\n",
      "✅ Done: Store 35, Dept 55\n",
      "🔄 Training on Store 35, Dept 27\n",
      "✅ Done: Store 35, Dept 27\n",
      "🔄 Training on Store 35, Dept 28\n",
      "✅ Done: Store 35, Dept 28\n",
      "🔄 Training on Store 35, Dept 29\n",
      "✅ Done: Store 35, Dept 29\n",
      "🔄 Training on Store 35, Dept 30\n",
      "✅ Done: Store 35, Dept 30\n",
      "🔄 Training on Store 35, Dept 31\n",
      "✅ Done: Store 35, Dept 31\n",
      "🔄 Training on Store 35, Dept 32\n",
      "✅ Done: Store 35, Dept 32\n",
      "🔄 Training on Store 35, Dept 33\n",
      "✅ Done: Store 35, Dept 33\n",
      "🔄 Training on Store 35, Dept 34\n",
      "✅ Done: Store 35, Dept 34\n",
      "🔄 Training on Store 35, Dept 35\n",
      "✅ Done: Store 35, Dept 35\n",
      "🔄 Training on Store 35, Dept 36\n",
      "✅ Done: Store 35, Dept 36\n",
      "🔄 Training on Store 35, Dept 38\n",
      "✅ Done: Store 35, Dept 38\n",
      "🔄 Training on Store 35, Dept 40\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import pandas as pd\n",
    "\n",
    "forecast_results = []\n",
    "\n",
    "# Loop through all store and department combinations\n",
    "for idx, row in store_dept_pairs.iterrows():\n",
    "    store_id = row['Store']\n",
    "    dept_id = row['Dept']\n",
    "\n",
    "    print(f\"🔄 Training on Store {store_id}, Dept {dept_id}\")\n",
    "\n",
    "    # Filter the full dataset\n",
    "    sales = df[(df['Store'] == store_id) & (df['Dept'] == dept_id)].sort_values('Date')\n",
    "\n",
    "    if len(sales) < 30:  # Skip short series\n",
    "        print(f\"⚠️ Not enough data for Store {store_id}, Dept {dept_id}\")\n",
    "        continue\n",
    "\n",
    "    # Set Date as index\n",
    "    sales.set_index('Date', inplace=True)\n",
    "\n",
    "    # Use 'Weekly_Sales' for training\n",
    "    train = sales['Weekly_Sales']\n",
    "    \n",
    "      # ✅ Check if train or test set is empty\n",
    "    if train.empty:\n",
    "        print(f\"⚠️ Skipping Store {store_id}, Dept {dept_id} — No train/test data\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Train SARIMAX model on full data\n",
    "        model = SARIMAX(train, order=(1, 1, 1), seasonal_order=(1, 1, 1, 52))\n",
    "        result = model.fit(disp=False)\n",
    "\n",
    "        # Forecast next 12 weeks\n",
    "        forecast = result.forecast(steps=12)\n",
    "\n",
    "        # Save results\n",
    "        forecast_results.append({\n",
    "            'Store': store_id,\n",
    "            'Dept': dept_id,\n",
    "            'Forecast': forecast.values\n",
    "        })\n",
    "\n",
    "        print(f\"✅ Done: Store {store_id}, Dept {dept_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Skipped Store {store_id}, Dept {dept_id} - Error: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42768a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = pd.DataFrame(forecast_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499a7719",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df.to_csv(os.path.join(data_path, \"store_dept_forecasts.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e6299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pick a specific Store and Dept\n",
    "example = forecast_results[0]  # or loop through a few\n",
    "\n",
    "# Get actual sales\n",
    "actual_sales = df[(df['Store'] == example['Store']) & (df['Dept'] == example['Dept'])].sort_values('Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot last 50 weeks + forecast\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(actual_sales['Date'][-50:], actual_sales['Weekly_Sales'][-50:], label='Actual Sales')\n",
    "plt.plot(pd.date_range(start=actual_sales['Date'].max(), periods=13, freq='W')[1:],  # skip the last actual week\n",
    "         example['Forecast'], label='Forecast', linestyle='--')\n",
    "\n",
    "plt.title(f\"Store {example['Store']}, Dept {example['Dept']}\")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Weekly Sales')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de26cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group forecasts by Store and sum the predicted values across departments\n",
    "store_forecasts = forecast_df.groupby('Store')['Forecast'].apply(\n",
    "    lambda x: sum(x.tolist())  # flatten and sum lists\n",
    ").reset_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "for _, row in store_forecasts.iterrows():\n",
    "    plt.plot(row['Forecast'], label=f\"Store {row['Store']}\")\n",
    "\n",
    "plt.title(\"Sales Forecast for All Stores (Summed Across Depts)\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Predicted Sales\")\n",
    "plt.legend(ncol=4, fontsize='small')  # Shrink legend if too many stores\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383d8570",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_stores = df.groupby('Store')['Weekly_Sales'].sum().sort_values(ascending=False).head(10)\n",
    "top_stores.plot(kind='bar', figsize=(10,5), title='Top 10 Stores by Total Sales')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0777550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'] = df['Date'].dt.month\n",
    "df['Year'] = df['Date'].dt.year\n",
    "monthly_sales = df.groupby(['Year', 'Month'])['Weekly_Sales'].sum().unstack(level=0)\n",
    "\n",
    "monthly_sales.plot(figsize=(12,6), title='Monthly Sales Trends (2010–2012)')\n",
    "plt.ylabel('Sales')\n",
    "plt.xlabel('Month')\n",
    "plt.xticks(range(1,13))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5042879c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ef517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
